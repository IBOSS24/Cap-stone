# SpaceX Falcon 9 ‚Äî First‚ÄëStage Landing Prediction üöÄ
_A Machine Learning capstone built from data collection ‚Üí wrangling ‚Üí EDA/SQL ‚Üí visualization ‚Üí geospatial mapping ‚Üí classification._

## Overview
This repository predicts **whether a Falcon 9 first stage lands successfully** (`Class ‚àà {0,1}`). It combines real data collection (API + web scraping), rigorous wrangling, exploratory analysis (including SQL-in-notebook), visualization, geospatial mapping with Folium, and a final ML model trained and evaluated on engineered features. The repo also includes an optional **Dash** dashboard for interactive exploration.

**Why this project matters:** recovering the booster saves millions. Predicting success helps analyze risk, identify drivers (payload, site, booster version), and communicate insights to stakeholders.

---

## What‚Äôs in this repo (your working files)
- **Data**
  - `dataset_part_2.csv` ‚Äî enriched dataset with core fields like `FlightNumber, Date, BoosterVersion, PayloadMass, Orbit, LaunchSite, Outcome, Flights, GridFins, Reused, Legs, LandingPad, Block, ReusedCount, Serial, Longitude, Latitude, Class` plus one‚Äëhot columns for booster serials.
  - `dataset_part_3.csv` ‚Äî modeling‚Äëready matrix with numerical/categorical features (including one‚Äëhot columns for `Serial_*`) used in training/evaluation.

- **Notebooks (by stage)**
  1. `jupyter-labs-spacex-data-collection-api.ipynb` ‚Äî Data collection via API (requests), JSON to tabular, initial cleaning.
  2. `jupyter-labs-webscraping.ipynb` ‚Äî Supplement data with web scraping (BeautifulSoup), parsing HTML tables/pages.
  3. `labs-jupyter-spacex-Data wrangling.ipynb` ‚Äî Cleaning, type casting, feature derivation, handling missingness; export to `dataset_part_2.csv`.
  4. `jupyter-labs-eda-sql-coursera_sqllite.ipynb` ‚Äî EDA using **SQLite** inside the notebook (SQL cells alongside pandas) to answer analytical questions.
  5. `Data_Visualization_lab.ipynb` ‚Äî Visual analytics: distributions, relationships, categorical contrasts; plots ready for reports.
  6. `lab_jupyter_launch_site_location.ipynb` ‚Äî **Folium** map of launch sites (MarkerCluster), success/failure coloring, tooltips/popups.
  7. `SpaceX_Machine Learning Prediction_Part_5.ipynb` ‚Äî Model training & evaluation for the landing classification task; confusion matrix, ROC/PR‚ÄëAUC, calibration and threshold search.

- **Apps / Scripts**
  - `SpaceX.py` ‚Äî Plotly **Dash** app (‚ÄúSpaceX Launch Records Dashboard‚Äù) for interactive filtering and scatter/pie views of payload vs success. Run with `python SpaceX.py`.  *(Code structure mirrors the standard Coursera lab app.)*

---

## Project structure (suggested)
```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # API/HTML outputs before cleaning
‚îÇ   ‚îú‚îÄ‚îÄ interim/                     # temporary merged/intermediate
‚îÇ   ‚îî‚îÄ‚îÄ processed/                   # dataset_part_2.csv, dataset_part_3.csv
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_collection_api.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_webscraping.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_wrangling.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_eda_sql.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_visualization.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 06_geospatial_folium.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 07_ml_prediction.ipynb
‚îú‚îÄ‚îÄ src/                             # optional: move reusable code here
‚îÇ   ‚îú‚îÄ‚îÄ features.py
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îî‚îÄ‚îÄ infer.py
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ dash_app.py                  # (rename of SpaceX.py if you prefer)
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                     # confusion matrix, ROC/PR, calibration
‚îÇ   ‚îî‚îÄ‚îÄ tables/                      # metrics summaries
‚îî‚îÄ‚îÄ README.md
```

> You already have files organized; the above is a ‚Äúcleaned‚Äù layout you can adopt progressively.

---

## Environment & setup

### Requirements (minimal)
```txt
python>=3.9
pandas
numpy
scikit-learn
matplotlib
seaborn
plotly
dash
folium
requests
beautifulsoup4
lxml
sqlalchemy
jupyter
joblib
```
Install:
```bash
pip install -r requirements.txt
# or, quickly:
pip install pandas numpy scikit-learn matplotlib seaborn plotly dash folium requests beautifulsoup4 lxml sqlalchemy jupyter joblib
```

### Trusting notebooks
If outputs (JS/HTML) don‚Äôt render, trust the notebook:
```bash
jupyter trust path/to/notebook.ipynb
```

---

## Reproducing the pipeline

### 1) Data collection
- Run `jupyter-labs-spacex-data-collection-api.ipynb` to pull launch data via an API, normalize JSON to tabular, and save a raw CSV.
- Run `jupyter-labs-webscraping.ipynb` to scrape supplemental attributes (e.g., tables with outcomes), merge with API data.

### 2) Wrangling & feature engineering
- Use `labs-jupyter-spacex-Data wrangling.ipynb` to clean types (dates/categoricals), fill/flag missingness, compute engineered features, and export **`dataset_part_2.csv`** to `data/processed/`.

### 3) EDA (including SQL)
- In `jupyter-labs-eda-sql-coursera_sqllite.ipynb`, run SQL queries against an in‚Äënotebook SQLite DB and cross‚Äëcheck with pandas for accuracy and performance.

### 4) Visualization
- Explore patterns in `Data_Visualization_lab.ipynb` (class imbalance, payload vs outcome, booster categories). Save charts to `reports/figures/`.

### 5) Geospatial mapping
- Open `lab_jupyter_launch_site_location.ipynb` to render a **Folium** map showing launch sites (MarkerCluster) colored by outcome; export to `reports/figures/launch_sites_map.html`.

### 6) Modeling & evaluation
- Train and evaluate in `SpaceX_Machine Learning Prediction_Part_5.ipynb` using `dataset_part_3.csv` (modeling‚Äëready features).
- Report: **Precision/Recall/F1**, **ROC‚ÄëAUC**, **PR‚ÄëAUC** (recommended under imbalance), confusion matrix, and **calibration** (Brier/log loss). Select threshold tied to the problem goal (e.g., favor recall).

---

## Example CLI (optional if you move logic to `src/`)
```bash
python -m src.train     --train data/processed/dataset_part_3.csv --model_out models/best_model.joblib --seed 42
python -m src.evaluate  --model models/best_model.joblib         --test  data/processed/dataset_part_3.csv --report_dir reports/
python -m src.infer     --model models/best_model.joblib         --input data/processed/dataset_part_3.csv --output predictions.csv
```

---

## Dash app (interactive)
Run the dashboard locally:
```bash
python SpaceX.py
# then open the URL shown in the terminal (usually http://127.0.0.1:8050)
```
The app provides:
- A **site dropdown** for ‚ÄúAll Sites‚Äù or a specific launch site
- A **pie chart** summarizing success counts
- A **payload range slider** and **scatter plot** showing correlation between payload and success, colored by booster version

> This follows the standard ‚ÄúSpaceX Launch Records Dashboard‚Äù structure from the lab code. Update `spacex_launch_dash.csv` path if needed, and ensure columns like `Payload Mass (kg)`, `Launch Site`, `class`, and `Booster Version Category` exist in your data.

---

## Results & reporting
- Place figures (confusion matrix, ROC/PR curves, reliability diagram) in `reports/figures/`.
- Summarize metrics in `reports/tables/` and the README.
- When reporting, prefer **PR‚ÄëAUC** for imbalanced positive class and document the **chosen threshold** and its business trade‚Äëoff.

---

## Tips & quality
- Use **stratified splits** and avoid leakage (fit scalers/encoders inside pipelines).
- Set **random seeds** throughout (`numpy`, `sklearn`) to improve reproducibility.
- Consider `GridSearchCV` / `RandomizedSearchCV` for tuning and log results.
- Add `requirements.txt` and optionally a Conda `environment.yml` for portability.

---

## Acknowledgments
- Educational SpaceX dataset and open web sources used for learning.
- pandas, scikit-learn, matplotlib, seaborn, plotly/dash, folium communities.

---

## License
MIT (or your preferred license).

